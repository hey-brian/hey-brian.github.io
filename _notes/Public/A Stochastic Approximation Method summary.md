---
title: A Stochastic Approximation Method summary
feed: hide
date : 2023-03-29
time : 07:39:00
tags : [summary]
format: list
comments: true
---

![](/attachments/Screenshot_2023-03-29_at_74210_AM_watermarked.jpeg)

(\### image from [A Stochastic Approximation Method(1951)](https://projecteuclid.org/euclid.aoms/1177729586))

Robbins와 Monro의 "A Stochastic Approximation Method" 논문은 확률적 근사 방법을 제안하고, 근사해의 수렴성과 안정성에 대해 분석하며 최적화 및 제어 분야에서 이를 적용할 수 있는 방법을 제안한다.

# Key Insights and Lessons Learned
- 확률적 근사 방법은 최적화 문제에서 일반적으로 사용되며, 수렴성이 높고 안정적인 방법이다.
- 확률적 근사 방법은 [[Gradient Descent|경사하강법]]과 유사하며, 보다 일반적인 문제에도 적용할 수 있다.
- 확률적 근사 방법은 머신러닝 및 통계학 분야에서 널리 사용되며, 다양한 응용이 있다.
- 확률 근사 방법론을 최적화 및 제어 분야에서 적용하는 기초를 제시했다.
- 이 논문에서 제시한 확률 근사 방법론은 불연속적인 최적화 문제를 효과적으로 해결할 수 있는 기술 중 하나이다.
- 확률 근사 방법론은 다양한 분야에서 활용되고 있으며, 특히 머신러닝에서는 확률적 경사 하강법과 유사한 개념으로 적용된다.

# Related papers
- Kushner, H. J., & Yin, G. G. (2003). Stochastic approximation algorithms and applications. Springer Science & Business Media.
- Bertsekas, D. P. (2011). Incremental gradient, subgradient, and proximal methods for convex optimization: a survey. Optimization for Machine Learning, 19-50.
- Spall, J. C. (2003). Introduction to stochastic search and optimization: estimation, simulation, and control. John Wiley & Sons.
- Nesterov, Y. (2018). Lectures on convex optimization (Vol. 137). Springer.

_끝_