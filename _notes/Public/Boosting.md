---
title: Boosting
feed: show
date : 2023-04-27
tags : [ğŸ“ï¸/ğŸŒ²ï¸, ML]
comments: true
---

# 1. Introduction
### 1.1 âœ‚ï¸TL;DR
- ì•½í•œ í•™ìŠµì(Weak learner)ë¥¼ ê°•í•œ í•™ìŠµì(Strong learner)ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ì§‘í•©
- ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ Boosting ì•Œê³ ë¦¬ì¦˜ ì¤‘ ê°€ì¥ ëŒ€í‘œì ì´ê³  íš¨ê³¼ì ì¸ ì•Œê³ ë¦¬ì¦˜ì´ [[AdaBoost]]

### 1.2 ğŸ”—Useful links
- [Wikipedia](https://en.wikipedia.org/wiki/Boosting_(machine_learning))

# 2. How It Works
### 2.1 ğŸ”‘Key 
- ê¸°ê³„ í•™ìŠµì—ì„œ ë¶€ìŠ¤íŒ…(Boosting)ì€ ì•™ìƒë¸” ë©”íƒ€ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ì§€ë„ í•™ìŠµì—ì„œ í¸í–¥ì„ ì£¼ë¡œ ì¤„ì´ê³  ë¶„ì‚°ë„ ì¤„ì´ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ì¼ì¢…ì´ë‹¤. 
	- **ì•½í•œ í•™ìŠµì(Weak learner)**: ë¬´ì‘ìœ„ë¡œ ì¶”ì¸¡í•˜ëŠ” ê²ƒë³´ë‹¤ëŠ” ì•„ì£¼ ì‚´ì§ ë” ì„±ëŠ¥ì´ ì¢‹ì€ ë¶„ë¥˜ê¸°
	- **ê°•í•œ í•™ìŠµì(Strong learner)**: ì„±ëŠ¥ì´ ì¢‹ì€ ë¶„ë¥˜ê¸°
- ê°œë… ë…¼ì˜ì˜ ì‹œì‘: Kearnsì™€ Valiantì˜ "ë‹¤ìˆ˜ì˜ ì•½í•œ í•™ìŠµìê°€ ëª¨ì¸ ì§‘í•©ì´ í•˜ë‚˜ì˜ ê°•í•œ í•™ìŠµìê°€ ë  ìˆ˜ ìˆëŠ”ê°€?"(1988, 1989)
- ê·¸ì— ëŒ€í•œ ëŒ€ë‹µ: 1990ë…„ì— Robert Schapireê°€ ê¸ì •ì ì¸ ëŒ€ë‹µ = Boosting ê°œë… ë“±ì¥ + ê¸°ê³„ í•™ìŠµ, í†µê³„í•™ì— ì˜í–¥
- ì´ˆê¸°ì— ì†Œê°œëœ ê°€ì„¤ ë¶€ìŠ¤íŒ… ë¬¸ì œëŠ” ì•½í•œ í•™ìŠµìë¥¼ ê°•í•œ í•™ìŠµìë¡œ **ë³€í™˜**í•˜ëŠ” ê³¼ì •ì„ ì˜ë¯¸í–ˆë‹¤.
	- *"Informally, the hypothesis boosting problem asks whether an efficient learning algorithm â€¦ that outputs a hypothesis whose performance is only slightly better than random guessing, i.e. a weak learner, implies the existence of an efficient algorithm that outputs a hypothesis of arbitrary accuracy, i.e. a strong learner."*

![](attachments/Pasted_image_20230428091750_watermarked.jpeg)

(\### image from [Wikipedia](https://en.wikipedia.org/wiki/Boosting_(machine_learning)))

# 3. Application
- [[AdaBoost]]


_ë_