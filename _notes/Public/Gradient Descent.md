---
title: Gradient Descent
feed: show
date : 2023-05-25
tags : [π“οΈ/π²οΈ, ML]
comments: true
---

# 1. Introduction
### 1.1 β‚οΈTL;DR
- ν•¨μμ κΈ°μΈκΈ° μ •λ³΄λ¥Ό μ΄μ©ν•μ—¬ loss functionμ μµμ†κ°’μ„ μ°Ύμ•„κ°€λ©° μµμ ν™”λ νλΌλ―Έν„°λ¥Ό μ°Ύλ” λ°©λ²•

### 1.2 π”—Useful links
- [Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent)

# 2. How It Works
### 2.1 π”‘Key 

> κ²½μ‚¬ ν•κ°•λ²•μ ν•µμ‹¬ μ•„μ΄λ””μ–΄λ” `ν•¨μμ κΈ°μΈκΈ°λ¥Ό λ”°λΌμ„ μµμ†κ°’μΌλ΅ μ μ§„μ μΌλ΅ μ΄λ™`

### 2.2 β›“οΈSteps 
1.  μ΄κΈ°μ—λ” νλΌλ―Έν„° κ°’μ„ μ„μλ΅ μ„¤μ •
2.  μ£Όμ–΄μ§„ μ†μ‹¤ ν•¨μμ κΈ°μΈκΈ°(gradient)λ¥Ό κ³„μ‚°
3.  κ·Έλ λ””μ–ΈνΈλ¥Ό μ΄μ©ν•μ—¬ νλΌλ―Έν„°λ¥Ό μ—…λ°μ΄νΈ. μ—…λ°μ΄νΈλ” κΈ°μΈκΈ°μ— ν•™μµλ¥ (learning rate)μ„ κ³±ν• κ°’λ§νΌ νλΌλ―Έν„°λ¥Ό μ΅°μ •.
4.  2~3λ‹¨κ³„λ¥Ό λ°λ³µν•μ—¬ μ†μ‹¤ ν•¨μμ κ°’μ΄ μµμ†ν™”λλ” νλΌλ―Έν„° κ°’ νƒμƒ‰

![](/attachments/Pasted_image_20230525071716_watermarked.jpeg)

(\### image from [Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent))

# 3. Pros and Cons
### 3.1 Pros
- λ‹¤μ–‘ν• μΆ…λ¥μ ν•¨μμ— μ μ© κ°€λ¥
- μλ ΄μ΄ λ³΄μ¥λλ” κ²½μ°μ—λ” μµμ κ°’ λ„λ‹¬ κ°€λ¥

### 3.2 Cons
- κΈ°μΈκΈ°μ— λ”°λΌ λ‹¨μν μ΄λ™ν•κΈ° λ•λ¬Έμ— μ§€μ—­ μµμ†κ°’μ— κ°‡ν μ μλ‹¤.
- ν•™μµλ¥  μ„¤μ •μ— λ”°λΌ μλ ΄ μ†λ„μ™€ μ„±λ¥μ΄ λ‹¬λΌμ§.

# 4. Application
- [[Stochastic Gradient Descent]] 

_λ_