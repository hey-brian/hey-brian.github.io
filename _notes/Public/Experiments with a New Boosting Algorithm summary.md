---
title: Experiments with a New Boosting Algorithm summary
feed: hide
date : 2023-03-28
time : 07:44:58
tags : [summary]
format: list
comments: true
---

![](/attachments/Screenshot_2023-03-28_at_105139_PM_watermarked.jpeg)

(\### image from [Experiments with a New Boosting Algorithm(1996)](https://citeseerx.ist.psu.edu/search_result?query=Experiments+with+a+New+Boosting+Algorithm+%281996%29%2C+Freund+and+Schapire&pdf=true))

AdaBoost는 이전의 부스팅 알고리즘과 비교하여 높은 성능을 보이며, 알고리즘이 간단하고 구현하기 쉽다는 AdaBoost 알고리즘의 실험결과를 제시한다.

# Key Insights and Lessons Learned
- AdaBoost 알고리즘은 간단하면서도 높은 성능을 보이는 부스팅 알고리즘이다.
- 부스팅은 일반적으로 다른 머신러닝 기법들과 비교하여 높은 정확도를 보인다.
- 다양한 데이터셋에서의 실험 결과를 통해 AdaBoost의 일반성을 입증했다.

# Related papers
- Freund, Y., & Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1), 119-139.
- Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media.
- Schapire, R. E., & Freund, Y. (2012). Boosting: foundations and algorithms. Courier Corporation.
- Breiman, L. (1996). Bagging predictors. Machine learning, 24(2), 123-140.
- Freund, Y., & Schapire, R. E. (1995). A desicion-theoretic generalization of on-line learning and an application to boosting. Proceedings of the Second European Conference on Computational Learning Theory, 23-37.

_끝_