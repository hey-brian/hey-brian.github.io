---
title: Support Vector Networks summary
feed: hide
date : 2023-03-27
time : 07:30:47
tags : []
format: list
comments: true
---

![](/attachments/Support_vector_networks_paper.jpeg)

Corinna Cortes와 Vladimir Vapnik이 1995년에 발표한 논문으로, **SVM(Support Vector Machines)을 이용하여 두 개의 클래스 사이에서 가장 좋은 분리 초평면을 찾는 새로운 분류 접근 방법을 소개**했다.

# <특징>
- SVM은 최대 마진 분류기를 찾기 위해 사용되며, 이는 **서로 다른 클래스에서 가장 가까운 데이터 포인트 사이의 거리를 최대화하는 초평면**이다.
- **커널 함수**를 사용하여 **비선형**적으로 구분되는 데이터를 처리할 수 있다.
- SVM은 다른 분류기와 비교하여 매우 높은 일반화 능력을 가지며, 작은 규모의 데이터 집합에서도 잘 작동한다.
- SVM은 일반적으로 데이터의 차원이 증가함에 따라 더 높은 계산 비용을 요구한다.
- SVM은 데이터의 분포와 클래스의 균형을 고려해야 한다.

# <관련된 논문>
- Schölkopf, B., & Smola, A. J. (2002). Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond. MIT press.
- Cristianini, N., & Shawe-Taylor, J. (2000). An introduction to support vector machines and other kernel-based learning methods. Cambridge university press.
- Vapnik, V. (2013). The nature of statistical learning theory. Springer Science & Business Media.
- Platt, J. C. (1999). Fast training of support vector machines using sequential minimal optimization. In Advances in kernel methods (pp. 185-208). MIT Press.
- Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.

_끝_