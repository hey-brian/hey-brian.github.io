---
title: Expectation Maximization
feed: show
date : 2023-05-30
time : 07:11:13
tags : []
format: list
comments: true
---

# 1. Introduction
### 1.1 β‚οΈTL;DR
- EM μ•κ³ λ¦¬μ¦μ€ λ°μ΄ν„°μ λ¶μ™„μ „μ„±μ΄λ‚ μ¨κ²¨μ§„ λ³€μμ— μμ΅΄ν•λ” κ²½μ°μ— μ‚¬μ©λλ©°, ν™•λ¥  λ¨λΈμ νλΌλ―Έν„° μ¶”μ •μ— μ‚¬μ©λλ” λ°λ³µμ μΈ μµμ ν™” μ•κ³ λ¦¬μ¦

### 1.2 π“Paper summary
- [[Maximum likelihood from incomplete data via the EM algorithm summary]]

### 1.3 π”—Useful links
- [Wikipedia](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)

# 2. How It Works
### 2.1 π”‘Key 

> "E(Expectation)" λ‹¨κ³„μ™€ "M(Maximization)" λ‹¨κ³„λ¥Ό λ°λ³µν•λ©°, νλΌλ―Έν„° κ°’μ„ μ μ§„μ μΌλ΅ μµμ ν™”ν•μ—¬ λ¨λΈμ„ ν•™μµ

### 2.2 β›“οΈSteps 
1. μ΄κΈ°μ—λ” νλΌλ―Έν„° κ°’μ„ μ„μλ΅ μ„¤μ •
2. `Eλ‹¨κ³„(Expectation Step)`: Eλ‹¨κ³„μ—μ„λ” ν„μ¬μ νλΌλ―Έν„° κ°’μ„ κΈ°λ°μΌλ΅ μ¨κ²¨μ§„ λ³€μμ— λ€ν• κΈ°λ€κ°’(Expectation)μ„ μ¶”μ •ν•λ‹¤. κΈ°λ€κ°’μ€ μ£Όμ–΄μ§„ λ°μ΄ν„°μ™€ νλΌλ―Έν„°λ¥Ό κΈ°λ°μΌλ΅ μ¨κ²¨μ§„ λ³€μμ ν™•λ¥  λ¶„ν¬λ¥Ό κ³„μ‚°ν•μ—¬ μ¨κ²¨μ§„ λ³€μμ κ°’μ— λ€ν• ν™•λ¥ μ  μμΈ΅μ„ μν–‰ν•λ‹¤.
3. `Mλ‹¨κ³„(Maximization Step)`: Mλ‹¨κ³„μ—μ„λ” Eλ‹¨κ³„μ—μ„ κ³„μ‚°ν• μ¨κ²¨μ§„ λ³€μμ κΈ°λ€κ°’μ„ μ‚¬μ©ν•μ—¬ νλΌλ―Έν„°λ¥Ό μµλ€ν™”(Maximization)ν•λ‹¤. μ¨κ²¨μ§„ λ³€μμ κΈ°λ€κ°’μ„ μ‚¬μ©ν•μ—¬ νλΌλ―Έν„°λ¥Ό μ΅°μ •ν•μ—¬ μ£Όμ–΄μ§„ λ°μ΄ν„°μ— λ€ν• κ°€λ¥λ„(likelihood)λ¥Ό μµλ€ν™”ν•λ” λ°©ν–¥μΌλ΅ νλΌλ―Έν„° κ°’μ„ μ—…λ°μ΄νΈν•λ‹¤.
4. 2~3λ‹¨κ³„λ¥Ό λ°λ³µν•μ—¬ νλΌλ―Έν„° κ°’μ΄ μλ ΄ν•  λ•κΉμ§€ λ°λ³µν•λ‹¤.

![](/attachments/EM_Clustering_of_Old_Faithful_data.gif)

(\### image from [Wikipedia](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm))

# 3. Pros and Cons
### 3.1 Pros
- λ¶μ™„μ „ν• λ°μ΄ν„° λλ” μ¨κ²¨μ§„ λ³€μκ°€ μλ” κ²½μ°μ—λ„ νλΌλ―Έν„°λ¥Ό μ¶”μ • κ°€λ¥
- μλ ΄μ΄ λ³΄μ¥λλ” κ²½μ°μ—λ” κµ­μ§€μ μΈ μµμ κ°’μ— λ„λ‹¬ κ°€λ¥ 

### 3.2 Cons
- μ΄κΈ° νλΌλ―Έν„° κ°’μ— λ―Όκ°ν•κ² λ°μ‘ν•  μ μλ‹¤.
- μλ ΄ μ†λ„κ°€ λλ¦΄ μ μλ‹¤.

# 4. Application
- ν΄λ¬μ¤ν„°λ§(Clustering): EM μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•μ—¬ λ°μ΄ν„°λ¥Ό ν΄λ¬μ¤ν„°λ΅ κ·Έλ£Ήν™”ν•λ” κ²½μ°, κ° ν΄λ¬μ¤ν„°λ” νΉμ •ν• ν™•λ¥  λ¶„ν¬λ¥Ό κ°€μ§€λ©°, λ°μ΄ν„° ν¬μΈνΈλ” κ° ν΄λ¬μ¤ν„°μ— μ†ν•  ν™•λ¥ μ„ κ°€μ§„λ‹¤. (ν΄λ¬μ¤ν„°λ§: μ μ‚¬ν• μ†μ„±μ„ κ°€μ§„ λ°μ΄ν„° ν¬μΈνΈλ¥Ό κ·Έλ£ΉμΌλ΅ κ·Έλ£Ήν•‘)
- μ μ¬ λ³€μ λ¨λΈ(Latent Variable Models): μ μ¬ λ³€μ λ¨λΈμ€ λ°μ΄ν„°μ— λ€ν• λ¶€λ¶„μ μΈ κ΄€μ°°λ§μ„ κ°€μ§€κ³  μ¨κ²¨μ§„(latent) λ³€μλ¥Ό μ¶”μ •ν•λ” λ¨λΈμ΄λ©°, EM μ•κ³ λ¦¬μ¦μ€ μ μ¬ λ³€μ λ¨λΈμ νλΌλ―Έν„° μ¶”μ •μ— μ‚¬μ©λλ‹¤. 
	- κ°€μ°μ‹μ• νΌν•© λ¨λΈ(Gaussian Mixture Model)μ€ λ°μ΄ν„°λ¥Ό μ—¬λ¬ κ°μ κ°€μ°μ‹μ• λ¶„ν¬λ¥Ό κ°€μ§„ ν΄λ¬μ¤ν„°λ΅ λ¨λΈλ§ν•λ” μ μ¬ λ³€μ λ¨λΈμ΄λ©°, μ΄ λ• EM μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•μ—¬ κ°€μ°μ‹μ• νΌν•© λ¨λΈμ νλΌλ―Έν„°λ¥Ό μ¶”μ •ν•λ‹¤.
- μ΄λ―Έμ§€ μ²λ¦¬(Image Processing): μ΄λ―Έμ§€ λ¶„ν• (image segmentation) λ¬Έμ μ—μ„ EM μ•κ³ λ¦¬μ¦μ€ μ΄λ―Έμ§€λ¥Ό μ„λ΅ λ‹¤λ¥Έ μμ—­μΌλ΅ λ¶„ν• ν•λ” λ° μ‚¬μ©λλ”λ°, κ° μμ—­μ€ νΉμ •ν• ν™•λ¥  λ¶„ν¬λ¥Ό λ”°λ¥΄λ©° EM μ•κ³ λ¦¬μ¦μ€ μμ—­μ νλΌλ―Έν„°λ¥Ό μ¶”μ •ν•μ—¬ μ΄λ―Έμ§€ λ¶„ν• μ„ μν–‰ν•λ‹¤.
- λ°μ΄ν„° λ³µμ›(Data Imputation): EM μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•μ—¬ κ²°μΈ΅μΉκ°€ μλ” λ°μ΄ν„°μ μ μ¬ λ³€μμ™€ νλΌλ―Έν„°λ¥Ό λ™μ‹μ— μ¶”μ •ν•μ—¬ λ°μ΄ν„°λ¥Ό λ³µμ›ν•  μ μλ‹¤. (κ²°μΈ΅μΉ: λ°μ΄ν„°μ—μ„ λ„λ½λ κ°’μ΄ μ΅΄μ¬)

_λ_